{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Matrix operations\n",
    "\n",
    "## 1.1 Create a 4*4 identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This project is designed to get familiar with python list and linear algebra\n",
    "#You cannot use import any library yourself, especially numpy\n",
    "\n",
    "A = [[1,2,3], \n",
    "     [2,3,3], \n",
    "     [1,2,5]]\n",
    "\n",
    "B = [[1,2,3,5], \n",
    "     [2,3,3,5], \n",
    "     [1,2,5,1]]\n",
    "\n",
    "#TODO create a 4*4 identity matrix \n",
    "I = [[1,0,0,0], \n",
    "     [0,1,0,0], \n",
    "     [0,0,1,0],\n",
    "     [0,0,0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 get the width and height of a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO Get the height and weight of a matrix.\n",
    "def shape(M):\n",
    "    r = len(M)\n",
    "    if isinstance(M[0],list):\n",
    "        c = len(M[0])\n",
    "    else:\n",
    "        c = 1\n",
    "    return r,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your shape function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 round all elements in M to certain decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO in-place operation, no return value\n",
    "# TODO round all elements in M to decPts\n",
    "def matxRound(M, decPts=4):\n",
    "    r,c = shape(M)\n",
    "    i = 0\n",
    "    while i<r:\n",
    "        j = 0\n",
    "        while j<c:\n",
    "            M[i][j] = round(M[i][j],decPts)\n",
    "            j += 1\n",
    "            pass\n",
    "        i += 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.009s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your matxRound function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_matxRound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 compute transpose of M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO compute transpose of M\n",
    "def transpose(M):\n",
    "    r,c = shape(M)\n",
    "    Mt = []\n",
    "    for e1 in range(0,c):\n",
    "        temp = []\n",
    "        for e2 in range(0,r):\n",
    "            temp.append(M[e2][e1])\n",
    "        Mt.append(temp)\n",
    "    return Mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.005s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your transpose function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 compute AB. return None if the dimensions don't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO compute matrix multiplication AB, return None if the dimensions don't match\n",
    "def listMultiply(A,B):\n",
    "    t = 0\n",
    "    l1=len(A)\n",
    "    i = 0\n",
    "    while i<l1:\n",
    "        t+=A[i]*B[i]\n",
    "        i+=1\n",
    "    return t\n",
    "\n",
    "def matxMultiply(A, B):\n",
    "    ar,ac = shape(A)\n",
    "    br,bc = shape(B)\n",
    "    \n",
    "    if not ac == br:\n",
    "        return None\n",
    "    else:\n",
    "        C = []\n",
    "        Bt = transpose(B)\n",
    "        for r in range(0,ar):\n",
    "            temp = []\n",
    "            for c in range(0,bc):\n",
    "                temp.append(listMultiply(A[r],Bt[c]))\n",
    "            C.append(temp)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.062s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your matxMultiply function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_matxMultiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2 Gaussian Jordan Elimination\n",
    "\n",
    "## 2.1 Compute augmented Matrix \n",
    "\n",
    "$ A = \\begin{bmatrix}\n",
    "    a_{11}    & a_{12} & ... & a_{1n}\\\\\n",
    "    a_{21}    & a_{22} & ... & a_{2n}\\\\\n",
    "    a_{31}    & a_{22} & ... & a_{3n}\\\\\n",
    "    ...    & ... & ... & ...\\\\\n",
    "    a_{n1}    & a_{n2} & ... & a_{nn}\\\\\n",
    "\\end{bmatrix} , b = \\begin{bmatrix}\n",
    "    b_{1}  \\\\\n",
    "    b_{2}  \\\\\n",
    "    b_{3}  \\\\\n",
    "    ...    \\\\\n",
    "    b_{n}  \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Return $ Ab = \\begin{bmatrix}\n",
    "    a_{11}    & a_{12} & ... & a_{1n} & b_{1}\\\\\n",
    "    a_{21}    & a_{22} & ... & a_{2n} & b_{2}\\\\\n",
    "    a_{31}    & a_{22} & ... & a_{3n} & b_{3}\\\\\n",
    "    ...    & ... & ... & ...& ...\\\\\n",
    "    a_{n1}    & a_{n2} & ... & a_{nn} & b_{n} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO construct the augment matrix of matrix A and column vector b, assuming A and b have same number of rows\n",
    "import copy\n",
    "def augmentMatrix(A, b):\n",
    "    ar,ac = shape(A)\n",
    "    i = 0\n",
    "    AA = copy.deepcopy(A)\n",
    "    while i<ar :\n",
    "        AA[i].append(b[i][0])\n",
    "        i += 1 \n",
    "    return AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.015s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your augmentMatrix function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_augmentMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Basic row operations\n",
    "- exchange two rows\n",
    "- scale a row\n",
    "- add a scaled row to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO r1 <---> r2\n",
    "# TODO in-place operation, no return value\n",
    "def swapRows(M, r1, r2):\n",
    "    temp = []\n",
    "    temp = M[r1]\n",
    "    M[r1] = M[r2]\n",
    "    M[r2] = temp\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your swapRows function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_swapRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO r1 <--- r1 * scale\n",
    "# TODO in-place operation, no return value\n",
    "def scaleRow(M, r, scale):\n",
    "    if scale == 0:\n",
    "        raise ValueError('scale can\\'t be 0')\n",
    "    else:\n",
    "        row,col=shape(M)\n",
    "        for i in range(0,len(M[r])):\n",
    "                M[r][i] = M[r][i]*scale\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your scaleRow function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_scaleRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO r1 <--- r1 + r2*scale\n",
    "# TODO in-place operation, no return value\n",
    "def addScaledRow(M, r1, r2, scale):\n",
    "    row,col=shape(M)\n",
    "    for i in range(0,len(M[r2])):\n",
    "            M[r1][i] += M[r2][i]*scale\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your addScaledRow function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_addScaledRow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3  Gauss-jordan method to solve Ax = b\n",
    "\n",
    "### Hint：\n",
    "\n",
    "Step 1: Check if A and b have same number of rows\n",
    "Step 2: Construct augmented matrix Ab\n",
    "\n",
    "Step 3: Column by column, transform Ab to reduced row echelon form [wiki link](https://en.wikipedia.org/wiki/Row_echelon_form#Reduced_row_echelon_form)\n",
    "    \n",
    "    for every column of Ab (except the last one)\n",
    "        column c is the current column\n",
    "        Find in column c, at diagonal and under diagonal (row c ~ N) the maximum absolute value\n",
    "        If the maximum absolute value is 0\n",
    "            then A is singular, return None （Prove this proposition in Question 2.4）\n",
    "        else\n",
    "            Apply row operation 1, swap the row of maximum with the row of diagonal element (row c)\n",
    "            Apply row operation 2, scale the diagonal element of column c to 1\n",
    "            Apply row operation 3 mutiple time, eliminate every other element in column c\n",
    "            \n",
    "Step 4: return the last column of Ab\n",
    "\n",
    "### Remark：\n",
    "We don't use the standard algorithm first transfering Ab to row echelon form and then to reduced row echelon form.  Instead, we arrives directly at reduced row echelon form. If you are familiar with the stardard way, try prove to yourself that they are equivalent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO implement gaussian jordan method to solve Ax = b\n",
    "\n",
    "\"\"\" Gauss-jordan method to solve x such that Ax = b.\n",
    "        A: square matrix, list of lists\n",
    "        b: column vector, list of lists\n",
    "        decPts: degree of rounding, default value 4\n",
    "        epsilon: threshold for zero, default value 1.0e-16\n",
    "        \n",
    "    return x such that Ax = b, list of lists \n",
    "    return None if A and b have same height\n",
    "    return None if A is (almost) singular\n",
    "\"\"\"\n",
    "def round_elements_in_list(l,decPts=4):\n",
    "    new_l = []\n",
    "    for e in l:\n",
    "        e = round(e[0],decPts)\n",
    "        new_l += [e]\n",
    "    return new_l\n",
    "\n",
    "def deep_copy(M):\n",
    "    mr,mc = shape(M)\n",
    "    new_r = []\n",
    "    new_m = []\n",
    "    for r in M:\n",
    "        new_r = r[:]\n",
    "        new_m.append(new_r)\n",
    "    return new_m\n",
    "\n",
    "def rre_form(M,decPts=4,epsilon=1.0e-16):\n",
    "    M_copy = M[:]\n",
    "    mr,mc = shape(M)\n",
    "    for j in range(mc):\n",
    "        current_column = get_current_column(M_copy,j)\n",
    "        max_under_diagnal_value,max_row = max_diagnal_and_under_value(current_column,j)\n",
    "        if max_under_diagnal_value == 0:\n",
    "            return None\n",
    "        else:\n",
    "            if j>(mr-1):\n",
    "                return M_copy\n",
    "            else:\n",
    "                swapRows(M_copy, j, max_row)\n",
    "                #scale = round(1./M_copy[j][j],decPts)\n",
    "                scale = 1./M_copy[j][j]\n",
    "                scaleRow(M_copy, j, scale)\n",
    "                eliminate_other_element_in_column(M_copy,j,epsilon,decPts)\n",
    "    return M_copy\n",
    "\n",
    "def eliminate_other_element_in_column(M,j,epsilon = 1.0e-16,decPts=4):\n",
    "    mr,mc = shape(M)\n",
    "    for i in range(mr):\n",
    "        if not i == j:\n",
    "            if abs(M[i][j]) > epsilon:\n",
    "                addScaledRow(M, i, j, round(-M[i][j],decPts))\n",
    "        else:\n",
    "            continue\n",
    "    return M\n",
    "\n",
    "def get_current_column(M,current_j):\n",
    "    mr,mc = shape(M)\n",
    "    if current_j>mc:\n",
    "        return None\n",
    "    else:\n",
    "        c = []\n",
    "        for i in range(mr):\n",
    "            c.append(M[i][current_j])\n",
    "        return c\n",
    "    \n",
    "def gcc(M,current_j):\n",
    "    mr,mc = shape(M)\n",
    "    if current_j>mc:\n",
    "        return None\n",
    "    else:\n",
    "        c = []\n",
    "        for i in range(mr):\n",
    "            c.append([M[i][current_j]])\n",
    "        return c\n",
    "    \n",
    "def max_diagnal_and_under_value(c,c1):\n",
    "    if c1>(len(c)-1):\n",
    "        return None,None\n",
    "    else:\n",
    "        max_value = 0\n",
    "        max_index = 0\n",
    "        for i in range(c1,len(c)):\n",
    "            if abs(c[i]) > max_value:\n",
    "                max_value = abs(c[i])\n",
    "                max_index = i\n",
    "        return max_value,max_index\n",
    "\n",
    "def gj_Solve(A, b, decPts=4, epsilon = 1.0e-16):\n",
    "    ar,ac = shape(A)\n",
    "    br = len(b)\n",
    "    # Step 1: Check if A and b have same number of rows \n",
    "    if not ar == br:\n",
    "        return None\n",
    "    else:\n",
    "        matxRound(A, decPts)\n",
    "        round_elements_in_list(b,decPts)\n",
    "        A_copy = deep_copy(A)\n",
    "        Ab = augmentMatrix(A_copy, b)\n",
    "        # Step 3: Column by column, transform Ab to reduced row echelon form\n",
    "        rre_Ab = rre_form(Ab,decPts,epsilon)\n",
    "        if rre_Ab == None:\n",
    "            return None\n",
    "        else:\n",
    "            # Step 4: return the last column of Ab\n",
    "            solution = gcc(rre_Ab,ac)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.056s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run following code to test your addScaledRow function\n",
    "%run -i -e test.py LinearRegressionTestCase.test_gj_Solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Prove the following proposition:\n",
    "\n",
    "**If square matrix A can be divided into four parts: ** \n",
    "\n",
    "$ A = \\begin{bmatrix}\n",
    "    I    & X \\\\\n",
    "    Z    & Y \\\\\n",
    "\\end{bmatrix} $, where I is the identity matrix, Z is all zero and the first column of Y is all zero, \n",
    "\n",
    "**then A is singular.**\n",
    "\n",
    "Hint: There are mutiple ways to prove this problem.  \n",
    "- consider the rank of Y and A\n",
    "- consider the determinate of Y and A \n",
    "- consider certain column is the linear combination of other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Please use latex （refering to the latex in problem may help）\n",
    "\n",
    "TODO Proof："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3 Linear Regression: \n",
    "\n",
    "## 3.1 Compute the gradient of loss function with respect to parameters \n",
    "## (Choose one between two 3.1 questions)\n",
    "\n",
    "We define loss funtion $E$ as \n",
    "$$\n",
    "E(m, b) = \\sum_{i=1}^{n}{(y_i - mx_i - b)^2}\n",
    "$$\n",
    "and we define vertex $Y$, matrix $X$ and vertex $h$ :\n",
    "$$\n",
    "Y =  \\begin{bmatrix}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "    ... \\\\\n",
    "    y_n\n",
    "\\end{bmatrix}\n",
    ",\n",
    "X =  \\begin{bmatrix}\n",
    "    x_1 & 1 \\\\\n",
    "    x_2 & 1\\\\\n",
    "    ... & ...\\\\\n",
    "    x_n & 1 \\\\\n",
    "\\end{bmatrix},\n",
    "h =  \\begin{bmatrix}\n",
    "    m \\\\\n",
    "    b \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Proves that \n",
    "$$\n",
    "\\frac{\\partial E}{\\partial m} = \\sum_{i=1}^{n}{-2x_i(y_i - mx_i - b)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial b} = \\sum_{i=1}^{n}{-2(y_i - mx_i - b)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial E}{\\partial m} \\\\\n",
    "    \\frac{\\partial E}{\\partial b} \n",
    "\\end{bmatrix} = 2X^TXh - 2X^TY\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Please use latex （refering to the latex in problem may help）\n",
    "\n",
    "TODO Proof："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Compute the gradient of loss function with respect to parameters \n",
    "## (Choose one between two 3.1 questions)\n",
    "We define loss funtion $E$ as \n",
    "$$\n",
    "E(m, b) = \\sum_{i=1}^{n}{(y_i - mx_i - b)^2}\n",
    "$$\n",
    "and we define vertex $Y$, matrix $X$ and vertex $h$ :\n",
    "$$\n",
    "Y =  \\begin{bmatrix}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "    ... \\\\\n",
    "    y_n\n",
    "\\end{bmatrix}\n",
    ",\n",
    "X =  \\begin{bmatrix}\n",
    "    x_1 & 1 \\\\\n",
    "    x_2 & 1\\\\\n",
    "    ... & ...\\\\\n",
    "    x_n & 1 \\\\\n",
    "\\end{bmatrix},\n",
    "h =  \\begin{bmatrix}\n",
    "    m \\\\\n",
    "    b \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Proves that \n",
    "$$\n",
    "E = Y^TY -2(Xh)^TY + (Xh)^TXh\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial h} = 2X^TXh - 2X^TY\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Please use latex （refering to the latex in problem may help）\n",
    "\n",
    "TODO Proof："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2  Linear Regression\n",
    "### Solve equation $X^TXh = X^TY $ to compute the best parameter for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO implement linear regression \n",
    "'''\n",
    "points: list of (x,y) tuple\n",
    "return m and b\n",
    "''' \n",
    "def linearRegression(p):\n",
    "    p_copy = p[:]\n",
    "    m=0\n",
    "    b=0\n",
    "    \n",
    "    X = gcc(p_copy,0)\n",
    "    for i in X:\n",
    "        i.append(1)\n",
    "        \n",
    "    XT = transpose(X)\n",
    "    \n",
    "    Y = gcc(p_copy,1)\n",
    "    \n",
    "    A = matxMultiply(XT,X)\n",
    "    \n",
    "    B = matxMultiply(XT,Y)\n",
    "    \n",
    "    s = gj_Solve(A,B)\n",
    "    \n",
    "    m=s[0]\n",
    "    b=s[1]\n",
    "    return m,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Test your linear regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkZBQQBcRCYn/D1K4VwwBYz2PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1101a4240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M after compute is:[0.40309555130866914]compare with ground truth: 0.4\n",
      "b after compute is:[0.12941885038840711]compare with ground truth: 0.2\n"
     ]
    }
   ],
   "source": [
    "#TODO Construct the linear function\n",
    "def linear(p,m,b):\n",
    "    h = [m,b]\n",
    "    p_copy=p[:]\n",
    "\n",
    "    for i in p_copy:\n",
    "        i.append(1)\n",
    "    \n",
    "    Y_predict = matxMultiply(p_copy,h)\n",
    "    \n",
    "    return Y_predict\n",
    "\n",
    "#TODO Construct points with gaussian noise\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "points = []\n",
    "points_with_noise = []\n",
    "\n",
    "xp=[]\n",
    "yp=[]\n",
    "\n",
    "xpn=[]\n",
    "ypn=[]\n",
    "\n",
    "for i in range(1,100):\n",
    "    w=[0.4,0.2]\n",
    "    \n",
    "    x = random.randint(1,100)\n",
    "    nx = random.gauss(0, 1)\n",
    "    xn = round(x+nx,2)\n",
    "    xp+=[x]\n",
    "    xpn+=[xn]\n",
    "    \n",
    "    y = round(x*w[0]+w[1],2)\n",
    "    ny = random.gauss(0, 1)\n",
    "    yn = round(y+ny,2)\n",
    "    yp+=[y]\n",
    "    ypn+=[yn]\n",
    "    \n",
    "    points.append([x]+[y])\n",
    "    points_with_noise.append([xn]+[yn])\n",
    "\n",
    "#TODO Compute m and b and compare with ground truth\n",
    "m,b=linearRegression(points_with_noise)\n",
    "\n",
    "x=[]\n",
    "for i in range(1,100):\n",
    "    x.append([i])\n",
    "\n",
    "y_predict = linear(x,m,b)\n",
    "\n",
    "\n",
    "plt.plot(gcc(x,0), y_predict)\n",
    "plt.plot(xpn,ypn,'o',color='red')\n",
    "plt.show()\n",
    "\n",
    "print('M after compute is:'+ str(m)+'compare with ground truth: 0.4')\n",
    "print('b after compute is:'+ str(b)+'compare with ground truth: 0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
